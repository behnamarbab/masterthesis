\section{Introduction}
\label{sec:ch4-intro}

% -T: Overview: Explain the details of this chapter

In this chapter, we explore the benchmarking and evaluation of our developed fuzzer. \texttt{FuzzBench} \cite{metzman2020fuzzbench}, is an automated benchmarking tool which selects a set of fuzzers and predefined benchmarks for fuzzing, and evaluates the performance of each fuzzer on each of the benchmarks in separate trials. In each trial, a fuzzer-specific binary with the according instrumentations is generated, and the fuzzer performs its testing until its time limit is ended. We can modify the amount of testing time in advance, and in this experiment, we have chosen 3 trials for each pair of (fuzzer, benchmark), which distinctively perform 12 of hours testing. In our experiments, we evaluated the performance of Waffle compared to \texttt{AFL}, \texttt{AFLPlusPlus}, and \texttt{AFLFast}. Each fuzzer performs it's testing on \texttt{freetype2-2017}, \texttt{libjpeg-turbo-07-2017}, \texttt{libpng-1.2.56}, and \texttt{libxml2-v2.9.2} (details in \cite{fuzzbench_benchmarks}). Fuzzbench generates pairwise reports for each fuzzer and targeted benchmarks.

In the next sections we first explain the configurations for comparing the performance of Waffle with other selected fuzzers. Next, an overview of the benchmarking is illustrated, and we analyze the results after. The results of the trials are reported by fuzzbench itself, but as the reports do not contain execution times, we analyze the generated queue entries of each of fuzzers, with the appropriate binaries. In the end, we contribute our resolutions of the tests.