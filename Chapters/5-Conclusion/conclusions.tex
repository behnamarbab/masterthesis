\section{Conclusions}
\label{sec:conclusions}
% -T: Explain the challenges in fuzz testing

In this thesis, we tried to propose a solution for coverage-based fuzz testing, which can generate resource-consuming inputs. Our implementations consider time as the main feature for resource consumptions. The challenges in our work contained modifications in instrumentation, fuzzing, and evaluating the results. The instrumentation collects the coverage information, and we insert instructions for tracking an Estimation of Resource Usages, during the preparation of the executives. After passing the resulting programs to our fuzzer, Waffle takes a greedy technique to increase the resource (time) usages by storing the recent most time-consuming inputs during fuzzing. This leads to performance guidance besides the available coverage guidance so that various regions of code are covered, and the regions are exploited for higher resource usage.

% -T: Challenges in evaluations

To mitigate the problem of comparing the performance of different fuzzers, we used FuzzBench for benchmarking Waffle. We added Waffle to the Fuzzbench's project and let our fuzzer start benchmarking with three other AFL-based fuzzers (AFL, AFLFast, AFL++). The results of the Fuzzbench's reports showed that although Waffle has a slightly slower input generation, it discovered more code coverages of some of the benchmarks. On the other hand, we post-processed the resulting inputs of each fuzzer to collect execution times. The results showed that Waffle could generate inputs with significantly higher execution time. We provided statistics that indicate the capability of Waffle in processing the time-consuming inputs.